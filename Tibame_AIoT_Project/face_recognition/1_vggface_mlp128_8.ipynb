{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_vggface_mlp128-8.ipynb ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWSB22LC-Ba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1e72378-c03d-4ec9-8b38-ddd677bdbed2"
      },
      "source": [
        "# age 分成8個 classes\n",
        "# mlp 每個全連接層的unit個數: 128 - 8\n",
        "# trainning: \n",
        "#   改用generator產生資料給fit_generator\n",
        "#   class_weight\n",
        "#   random_state\n",
        "#   callback: Early Stop, model.save\n",
        "\n",
        "\n",
        "#用少量資料\n",
        "FULL_DATA = 0\n",
        "per_cls = 600\n",
        "#用全部資料\n",
        "#FULL_DATA = 1\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 2\n",
        "model_folder_path = 'drive/My Drive/Tibame_AIoT_Project/face'\n",
        "img_folder_path = 'drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.29 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bv3RgQfbZ_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0ed0dd1f-205b-41c7-ec43-909291491a44"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "time: 3.15 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri1ni0ZmaYPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "44717cd3-0d6a-4b01-c21d-7c3667caa542"
      },
      "source": [
        "# to measure execution time\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 2.57 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIxoBByJgDOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "ca393277-2804-4c7e-9e03-1f75d3dffa5e"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Sep  5 04:41:18 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    34W / 250W |   8745MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "time: 153 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enr3u7SZ0rHX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "40a93fd3-ae91-484d-b177-0b2e3c374037"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
            "time: 2.66 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HiBB7Hk1Cr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bdb0fb0e-52e7-4405-ad70-d23f29e50e01"
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "import keras\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
        "from keras.layers import Conv2D, AveragePooling2D, BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras import metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "from glob import glob\n",
        "import os\n",
        "from mtcnn import MTCNN\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 23.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfiio5_KHufK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85ceb701-3688-4b78-e200-f6e81b304fda"
      },
      "source": [
        "df = pd.read_csv('drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/age_gender_wiki.csv')\n",
        "df_under10 = pd.read_csv('drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/age_gender_imdb_under10.csv')\n",
        "df_over70 = pd.read_csv('drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/age_gender_imdb_over70.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 56.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPi60EWkDL6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c552b28d-0e6a-4c7c-e451-c62ecf9f2f20"
      },
      "source": [
        "df = pd.concat([df, df_under10, df_over70])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.18 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vj29J-vpoyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59a8505d-0738-403f-a28e-8b86679a8856"
      },
      "source": [
        "#some guys seem to be greater than 100. some of these are paintings. remove these old guys\n",
        "df = df[df['age'] <= 100]\n",
        " \n",
        "#some guys seem to be unborn in the data set\n",
        "df = df[df['age'] > 0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.15 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI0vTSSFtF3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "9b91bdaa-1994-4bb4-97aa-1edf529a2c07"
      },
      "source": [
        "# 每10歲分一類,70歲以上歸為同一類,共8類\n",
        "df['age_grp'] = pd.cut(df['age'], bins=[0,10,20,30,40,50,60,70,110], right=False)\n",
        "le = LabelEncoder()\n",
        "le.fit(df['age_grp'].astype('str'))\n",
        "df['age_cls'] = le.transform(df['age_grp'].astype('str'))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_path</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>age_grp</th>\n",
              "      <th>age_cls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wiki_crop/17/10000217_1981-05-05_2009.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>[20, 30)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wiki_crop/12/100012_1948-07-03_2008.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wiki_crop/16/10002116_1971-05-31_2012.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>[40, 50)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wiki_crop/02/10002702_1960-11-09_2012.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wiki_crop/41/10003541_1937-09-27_1971.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>[30, 40)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2268</th>\n",
              "      <td>imdb_crop/78/nm0498278_rm974293248_1922-12-28_...</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>[70, 110)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2269</th>\n",
              "      <td>imdb_crop/19/nm0694619_rm3523791616_1942-11-2_...</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>[70, 110)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2270</th>\n",
              "      <td>imdb_crop/19/nm0694619_rm3574123264_1942-11-2_...</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>[70, 110)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2271</th>\n",
              "      <td>imdb_crop/56/nm0792556_rm551744512_1928-6-12_2...</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>[70, 110)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2272</th>\n",
              "      <td>imdb_crop/92/nm0891092_rm609007616_1923-4-4_20...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>[70, 110)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35288 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              full_path  ...  age_cls\n",
              "0             wiki_crop/17/10000217_1981-05-05_2009.jpg  ...        2\n",
              "1               wiki_crop/12/100012_1948-07-03_2008.jpg  ...        5\n",
              "2             wiki_crop/16/10002116_1971-05-31_2012.jpg  ...        4\n",
              "3             wiki_crop/02/10002702_1960-11-09_2012.jpg  ...        5\n",
              "4             wiki_crop/41/10003541_1937-09-27_1971.jpg  ...        3\n",
              "...                                                 ...  ...      ...\n",
              "2268  imdb_crop/78/nm0498278_rm974293248_1922-12-28_...  ...        7\n",
              "2269  imdb_crop/19/nm0694619_rm3523791616_1942-11-2_...  ...        7\n",
              "2270  imdb_crop/19/nm0694619_rm3574123264_1942-11-2_...  ...        7\n",
              "2271  imdb_crop/56/nm0792556_rm551744512_1928-6-12_2...  ...        7\n",
              "2272  imdb_crop/92/nm0891092_rm609007616_1923-4-4_20...  ...        7\n",
              "\n",
              "[35288 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "stream",
          "text": [
            "time: 480 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBOpqcMoS90h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "d95ae7a6-8793-47f1-e169-87a0911f7a14"
      },
      "source": [
        "df['age_cls'].value_counts().sort_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      877\n",
              "1     2125\n",
              "2    11411\n",
              "3     6625\n",
              "4     4681\n",
              "5     3420\n",
              "6     2174\n",
              "7     3975\n",
              "Name: age_cls, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "stream",
          "text": [
            "time: 7.97 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynsfUWLDp4r7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "af28e11e-3330-4631-a743-6cc206b6310e"
      },
      "source": [
        "histogram_age = df['age_cls'].hist(bins=df['age_cls'].nunique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 208 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSCJlWc444MN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "73f2fb06-a373-450d-aebb-8546ca994182"
      },
      "source": [
        "#先用少量資料比較不同模型:\n",
        "#每個類別各取部分資料,用train_test_split來切train and test\n",
        "df_0 = df[df['age_cls'] == 0]\n",
        "df_1 = df[df['age_cls'] == 1]\n",
        "df_2 = df[df['age_cls'] == 2]\n",
        "df_3 = df[df['age_cls'] == 3]\n",
        "df_4 = df[df['age_cls'] == 4]\n",
        "df_5 = df[df['age_cls'] == 5]\n",
        "df_6 = df[df['age_cls'] == 6]\n",
        "df_7 = df[df['age_cls'] == 7]\n",
        "# train and val data\n",
        "if FULL_DATA == 1:\n",
        "    train_df = pd.concat([df_0[:-100], df_1[:-100], df_2[:-100], df_3[:-100], \n",
        "        df_4[:-100], df_5[:-100], df_6[:-100], df_7[:-100] ])    \n",
        "else:    \n",
        "    #先用少量資料比較不同模型\n",
        "    train_df = pd.concat([df_0[:per_cls], df_1[:per_cls], df_2[:per_cls], df_3[:per_cls], \n",
        "        df_4[:per_cls], df_5[:per_cls], df_6[:per_cls], df_7[:per_cls] ])\n",
        "# predict data: 每個類別保留最後100筆資料作為predict用\n",
        "predict_df = pd.concat([df_0[-100:], df_1[-100:], df_2[-100:], df_3[-100:], \n",
        "        df_4[-100:], df_5[-100:], df_6[-100:], df_7[-100:] ])\n",
        "x_pre, y_pre = np.array(predict_df['full_path']), np.array(predict_df['age_cls'])\n",
        "print(\"train:\", len(train_df), \"predict:\", len(predict_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 4800 predict: 800\n",
            "time: 65.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PQi3zwjxagcW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "743295b1-b98f-4047-f79a-02b89ccb6eaa"
      },
      "source": [
        "# 處理答案 把它轉成one-hot (後面再做)\n",
        "# y_train_category = to_categorical(df['age_cls'], num_classes=8)\n",
        "\n",
        "# 切分訓練data\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(train_df['full_path']), np.array(train_df['age_cls']), test_size=0.2, random_state=0)\n",
        "\n",
        "print(x_train[0], x_test[0], y_train[0], y_test[0])\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imdb_crop/14/nm0001014_rm4047346176_1970-3-27_1975.jpg wiki_crop/02/25072702_1983-02-15_2014.jpg 0 3\n",
            "(3840,) (960,) (3840,) (960,)\n",
            "time: 8.17 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZJoKwSbtpb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f40e00e1-2b7b-42c4-9c7b-11303295a7a4"
      },
      "source": [
        "detector = MTCNN()\n",
        "#feature_extractor = load_model(os.path.join(model_folder_path, 'facenet_keras.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 296 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DypYAJ7cJlrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "20d7471d-1901-4fa4-a3ea-745b0db21bfd"
      },
      "source": [
        "# VGGFace: https://github.com/rcmalli/keras-vggface\n",
        "!pip install keras_vggface\n",
        "!pip install keras_applications\n",
        "\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "feature_extractor = VGGFace(model='resnet50', include_top=False, \n",
        "            input_shape=(224, 224, 3), pooling='avg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_vggface in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (3.13)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.4.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.18.5)\n",
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications) (1.15.0)\n",
            "time: 7.15 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOgsPn1i3E21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b196ec3-d3c6-4c67-8a3d-d41ccd0b82e0"
      },
      "source": [
        "feature_extractor.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vggface_resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 55, 55, 64)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 55, 55, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 55, 55, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 55, 55, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 28, 28, 512)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 28, 28, 512)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 28, 28, 512)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 28, 28, 512)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 14, 14, 1024) 0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 7, 7, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,561,152\n",
            "Trainable params: 23,508,032\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "time: 99.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iJ6QxgZ_8iI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdb7a944-928b-41de-b3c8-d5bbe4360a66"
      },
      "source": [
        "# 固定pre-train model的參數\n",
        "for lyr in feature_extractor.layers:\n",
        "    lyr.trainable = False\n",
        "\n",
        "# BN\n",
        "x = BatchNormalization()(feature_extractor.output)    \n",
        "    \n",
        "# MLP    \n",
        "# x = Flatten()(x)\n",
        "\n",
        "#x = Dense(units=2048, activation='relu')(x)\n",
        "#x = Dense(units=512, activation='relu')(x)\n",
        "x = Dense(units=128, activation='relu')(x)\n",
        "x = Dense(units=8, activation='softmax')(x)\n",
        "age_model = Model(inputs=feature_extractor.input, outputs=x)   \n",
        "age_model.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 55, 55, 64)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 55, 55, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 55, 55, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 55, 55, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 28, 28, 512)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 28, 28, 512)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 28, 28, 512)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 28, 28, 512)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 14, 14, 1024) 0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 7, 7, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2048)         8192        global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 128)          262272      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 8)            1032        dense_16[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,832,648\n",
            "Trainable params: 267,400\n",
            "Non-trainable params: 23,565,248\n",
            "__________________________________________________________________________________________________\n",
            "time: 226 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs6tioz-AvmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7de25806-69ad-42de-e69b-ce81f4b9f6ac"
      },
      "source": [
        "age_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "age_model.load_weights(os.path.join(model_folder_path,'1_vggface_weight_mlp128-8_cls600.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 14.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Mn0wTy5Bze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f90edacc-124a-4047-883a-825fe957b106"
      },
      "source": [
        "# 資料預處理 for facenet?\n",
        "# Standardization\n",
        "def preprocess(imgs): \n",
        "    for i in range(imgs.shape[0]):\n",
        "        # standardization\n",
        "        img = imgs[i]\n",
        "        mean, std = img.mean(), img.std()\n",
        "        img = (img - mean) / std\n",
        "        imgs[i] = img\n",
        "    return imgs\n",
        "# Normalization\n",
        "def normalize(img):\n",
        "    return img / 255.\n",
        "\n",
        "# -1 <= x <= 1\n",
        "def preprocess_1(imgs):\n",
        "    x = np.array(imgs, dtype = float)\n",
        "    x /= 127.5\n",
        "    x -= 1.\n",
        "    return x    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 6.42 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evAgdxQ20ICI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ae5c4e85-8df4-4301-9154-00794f5ae89b"
      },
      "source": [
        "# detect face\n",
        "def detect_faces(img):\n",
        "    face_imgs = []\n",
        "    results = detector.detect_faces(img)\n",
        "    # extract the bounding box from the first face\n",
        "    # print('# of faces: ', len(results))\n",
        "    for i in range(len(results)):\n",
        "        x1, y1, width, height = results[i]['box']\n",
        "        x2, y2 = x1 + width, y1 + height\n",
        "        patch = img[y1:y2, x1:x2] # crop face\n",
        "        face_imgs.append(patch)\n",
        "    return face_imgs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.62 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBpYGPqZDTkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9859134b-55c7-44e2-8008-dffd154dc470"
      },
      "source": [
        "def data_generator(data_paths, y, batch_size=BATCH_SIZE):\n",
        "    '''data generator for fit_generator'''\n",
        "    n = len(data_paths)\n",
        "    i = 0\n",
        "    data_paths = data_paths\n",
        "    \n",
        "    while True:\n",
        "        x_ori, x_norm, y_ori = [], [], []\n",
        "        i_batch = i\n",
        "        for b in range(batch_size):\n",
        "            path = data_paths[i]\n",
        "            #print(\"idx:\", i, \"cls:\", y[i], path)\n",
        "        \n",
        "            # 讀取圖片,切下臉的部分,並使用借來的模型的預處理方式來作預處理           \n",
        "            img = cv2.imread(os.path.join(img_folder_path,path))[:,:,::-1]\n",
        "            \n",
        "            # plt.imshow(img)\n",
        "            # plt.show()\n",
        "            faces = detect_faces(img)\n",
        "            if len(faces) == 0 or faces[0].shape[0] == 0:\n",
        "                print('No face')\n",
        "                i = (i+1) % n\n",
        "                continue   \n",
        "            img_crop = cv2.resize(faces[0], (IMG_SIZE, IMG_SIZE))\n",
        "            # plt.imshow(faces[0])\n",
        "            # plt.show()\n",
        "\n",
        "            # 使用借來的模型的預處理方式來作預處理\n",
        "            img_pre = preprocess_input(np.array(img_crop,dtype=float))\n",
        "\n",
        "            # 把原圖留下來\n",
        "            x_ori.append(img)\n",
        "            x_norm.append(img_pre)\n",
        "            y_ori.append(y[i])\n",
        "            \n",
        "            i = (i+1) % n\n",
        "\n",
        "        # print(\"len(image_data)\",len(x_ori))\n",
        "        # plt.figure(figsize=(10, 40))\n",
        "        # for j,m in enumerate(x_ori):\n",
        "        #     plt.subplot(1, BATCH_SIZE, (j%BATCH_SIZE)+1)\n",
        "        #     plt.title(\"idx:{} y:{}\".format(i_batch+j, y[i_batch+j]))\n",
        "        #     plt.axis(\"off\")\n",
        "        #     plt.imshow(m)\n",
        "        # plt.show()    \n",
        "        y_category = to_categorical(y_ori, num_classes=8)    \n",
        "        yield np.array(x_norm), np.array(y_category)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 30 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DidZIPzKHzS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94586dd2-9e0d-438c-cebe-073894e2f65e"
      },
      "source": [
        "# 用generator產生資料\n",
        "generator_train = data_generator(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "generator_test = data_generator(x_test, y_test, batch_size=BATCH_SIZE)\n",
        "type(generator_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "stream",
          "text": [
            "time: 11.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEWln4Tua3dg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f42fcce8-3522-4909-b00e-8f25e7f8c6f6"
      },
      "source": [
        "if FULL_DATA == 1:\n",
        "    weights = {0:12., 1:5., 2:1., 3:2., 4:3., 5:4., 6:6., 7:3.}\n",
        "else:    \n",
        "    # for temp\n",
        "    weights = {0:1., 1:1., 2:1., 3:1., 4:1., 5:1., 6:1., 7:1.}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.51 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc_L3HTVMio7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "bbeeaaf2-1edb-4c5a-e87b-a28a285c7640"
      },
      "source": [
        "# fit_generator\n",
        "checkpoint = ModelCheckpoint(os.path.join(model_folder_path,\"1_vggface_mlp128-8_epoch.h5\"), \n",
        "                save_best_only=False)   #Defaults: save_freq='epoch', save_weights_only=False\n",
        "earlystop = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "logs = age_model.fit(generator_train,\n",
        "                epochs=EPOCHS,\n",
        "                steps_per_epoch=len(x_train)//BATCH_SIZE,\n",
        "                validation_data=generator_test,\n",
        "                validation_steps=len(x_test)//BATCH_SIZE,\n",
        "                class_weight=weights,\n",
        "                #validation_split=0.1,\n",
        "                callbacks=[checkpoint, earlystop] \n",
        "                )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 1789 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3d8fd5ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 1790 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3d8fad8950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "  4/960 [..............................] - ETA: 19:17 - loss: 3.3081 - accuracy: 0.1250No face\n",
            " 29/960 [..............................] - ETA: 25:10 - loss: 2.3271 - accuracy: 0.3043No face\n",
            "149/960 [===>..........................] - ETA: 48:55 - loss: 2.3285 - accuracy: 0.3384No face\n",
            "206/960 [=====>........................] - ETA: 43:45 - loss: 2.2429 - accuracy: 0.3508No face\n",
            "258/960 [=======>......................] - ETA: 39:34 - loss: 2.2450 - accuracy: 0.3551No face\n",
            "262/960 [=======>......................] - ETA: 39:15 - loss: 2.2536 - accuracy: 0.3547No face\n",
            "310/960 [========>.....................] - ETA: 35:49 - loss: 2.2343 - accuracy: 0.3549No face\n",
            "319/960 [========>.....................] - ETA: 35:16 - loss: 2.2236 - accuracy: 0.3562No face\n",
            "398/960 [===========>..................] - ETA: 30:23 - loss: 2.1390 - accuracy: 0.3725No face\n",
            "671/960 [===================>..........] - ETA: 15:12 - loss: 2.0076 - accuracy: 0.3847No face\n",
            "680/960 [====================>.........] - ETA: 14:42 - loss: 2.0036 - accuracy: 0.3841No face\n",
            "811/960 [========================>.....] - ETA: 7:46 - loss: 1.9381 - accuracy: 0.3882No face\n",
            "874/960 [==========================>...] - ETA: 4:28 - loss: 1.9044 - accuracy: 0.3918No face\n",
            "934/960 [============================>.] - ETA: 1:21 - loss: 1.8764 - accuracy: 0.3935No face\n",
            "960/960 [==============================] - ETA: 0s - loss: 1.8679 - accuracy: 0.3944No face\n",
            "No face\n",
            "No face\n",
            "No face\n",
            "960/960 [==============================] - 3716s 4s/step - loss: 1.8679 - accuracy: 0.3944 - val_loss: 1.4497 - val_accuracy: 0.4780\n",
            "time: 1h 2min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXsF6L2e-vzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d213d67b-eaa2-4b67-981d-91c62655c9eb"
      },
      "source": [
        "age_model.save_weights(os.path.join(model_folder_path,'1_vggface_weight_mlp128-8_cls600.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.54 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veQ_S9mOWx0B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "77234212-e2f9-4b87-828a-2fe59eb2cd14"
      },
      "source": [
        "cur_train_idx = 0\n",
        "cur_test_idx = 0\n",
        "def get_data(x, y, batch=20, IMG_SIZE=160, test=1):\n",
        "    # 要注意 numpy 中的 randint 的上限是不包含的 和一般的randint不同\n",
        "    # numpy array 的索引可以是個 list, 即可同時取出不只一個元素\n",
        "    global cur_train_idx, cur_test_idx\n",
        "    print(\"cur train/test idx:\", cur_train_idx, cur_test_idx)    \n",
        "    if test == 0:\n",
        "        #idx = np.random.randint(0, len(x), batch)\n",
        "        idx = list(range(cur_train_idx, cur_train_idx+batch, 1))\n",
        "        cur_train_idx = (cur_train_idx + batch) % len(x)\n",
        "    else:\n",
        "        idx = np.random.randint(0, len(x), batch)\n",
        "        #idx = list(range(cur_test_idx, cur_test_idx+batch, 1))\n",
        "        cur_test_idx += batch\n",
        "\n",
        "    #print(\"idx:\", idx, x[idx], y[idx])\n",
        "    x_idx = x[idx]\n",
        "    y_idx = y[idx]\n",
        "    x_ori, x_norm, y_ori = [], [], y_idx\n",
        "    for i,p in enumerate(x_idx):\n",
        "        print(p)\n",
        "        # 讀取圖片,切下臉的部分,並使用借來的模型的預處理方式來作預處理\n",
        "        img = np.array(cv2.imread(os.path.join(img_folder_path,p))[:,:,::-1])\n",
        "        # plt.imshow(img)\n",
        "        # plt.show()\n",
        "        faces = detect_faces(img)\n",
        "        if len(faces) == 0 or faces[0].shape[0] == 0:\n",
        "            print('No face')\n",
        "            continue   \n",
        "        img = cv2.resize(faces[0], (IMG_SIZE, IMG_SIZE))\n",
        "        # plt.imshow(faces[0])\n",
        "        # plt.show()\n",
        "\n",
        "        # 使用借來的模型的預處理方式來作預處理\n",
        "        img_pre = preprocess_input(np.array(img,dtype=float))\n",
        "        #img_pre = preprocess_1(img)\n",
        "        #img_pre = normalize(img)\n",
        "        \n",
        "        # 把原圖留下來\n",
        "        x_ori.append(img)\n",
        "        x_norm.append(img_pre)\n",
        "    return np.array(x_ori), np.array(x_norm), np.array(y_ori)\n",
        "\n",
        "# 取出要用來預測的資料\n",
        "x_ori_batch, x_batch, y_batch = get_data(x_pre, y_pre, batch=20, IMG_SIZE=224) \n",
        "print(y_batch)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cur train/test idx: 0 0\n",
            "wiki_crop/46/39990446_1913-04-27_1940.jpg\n",
            "imdb_crop/41/nm0286941_rm3966027776_1960-4-14_1970.jpg\n",
            "wiki_crop/04/469704_1991-02-17_2010.jpg\n",
            "wiki_crop/80/999980_1954-06-11_2008.jpg\n",
            "wiki_crop/93/4893_1952-03-22_2014.jpg\n",
            "wiki_crop/20/3590120_1990-09-21_2009.jpg\n",
            "wiki_crop/71/2997471_1980-07-05_2012.jpg\n",
            "wiki_crop/59/37920859_1955-06-16_2008.jpg\n",
            "imdb_crop/08/nm5583008_rm2864957952_2004-12-13_2014.jpg\n",
            "wiki_crop/25/28924225_1998-08-25_2013.jpg\n",
            "wiki_crop/10/39992510_1987-04-13_2007.jpg\n",
            "imdb_crop/78/nm0498278_rm2699400960_1922-12-28_2008.jpg\n",
            "wiki_crop/58/199558_1951-04-01_2004.jpg\n",
            "wiki_crop/66/37963966_1961-03-29_2012.jpg\n",
            "imdb_crop/45/nm4682545_rm1570754560_2007-6-6_2009.jpg\n",
            "wiki_crop/01/39990201_1975-08-02_2014.jpg\n",
            "imdb_crop/13/nm0889513_rm3106703360_1928-5-30_2008.jpg\n",
            "wiki_crop/02/29971102_1961-04-13_2010.jpg\n",
            "wiki_crop/90/4991590_1976-03-25_2012.jpg\n",
            "imdb_crop/41/nm0286941_rm4083468288_1960-4-14_1970.jpg\n",
            "[2 0 1 5 6 1 3 5 0 1 1 7 5 5 0 3 7 4 3 0]\n",
            "time: 15.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0VkMu89Pn36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3485e98e-0322-4591-cd2d-390b77cec47a"
      },
      "source": [
        "# predict\n",
        "pre = age_model.predict(x_batch).argmax(axis=-1)\n",
        "pre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 1, 4, 5, 0, 3, 6, 1, 1, 1, 7, 6, 5, 4, 3, 6, 2, 4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "stream",
          "text": [
            "time: 1.29 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pFTzAkoWIiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "eced4826-a5d8-4c4d-f94d-ea10608493e9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "pd.DataFrame(confusion_matrix(y_batch, pre),\n",
        "            index=[\"{}(真實)\".format(i) for i in range(8)],\n",
        "            columns=[\"{}(預測)\".format(i) for i in range(8)] \n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0(預測)</th>\n",
              "      <th>1(預測)</th>\n",
              "      <th>2(預測)</th>\n",
              "      <th>3(預測)</th>\n",
              "      <th>4(預測)</th>\n",
              "      <th>5(預測)</th>\n",
              "      <th>6(預測)</th>\n",
              "      <th>7(預測)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0(真實)</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1(真實)</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2(真實)</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3(真實)</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4(真實)</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5(真實)</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6(真實)</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7(真實)</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0(預測)  1(預測)  2(預測)  3(預測)  4(預測)  5(預測)  6(預測)  7(預測)\n",
              "0(真實)      1      2      0      0      1      0      0      0\n",
              "1(真實)      1      3      0      0      0      0      0      0\n",
              "2(真實)      0      0      1      0      0      0      0      0\n",
              "3(真實)      0      0      0      2      1      0      0      0\n",
              "4(真實)      0      0      1      0      0      0      0      0\n",
              "5(真實)      0      0      0      0      1      1      2      0\n",
              "6(真實)      0      0      0      0      0      1      0      0\n",
              "7(真實)      0      0      0      0      0      0      1      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "stream",
          "text": [
            "time: 24.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVTIZJsXZyjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veqfvA2J2UB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(x, y):\n",
        "    sum_square = np.sum(np.square(x - y), keepdims=True)\n",
        "    return np.sqrt(sum_square)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ic1ekdt2Xli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_age(img):\n",
        "    img_size = 100\n",
        "    img = normalize(img)\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    model_input = np.zeros((1, img_size, img_size, 3))\n",
        "    model_input[0] = img\n",
        "    ages = age_model.predict(model_input)\n",
        "    print('age: ', ages.argmax(axis=-1))\n",
        "    return \n",
        "\n",
        "# def predict_gender(img):\n",
        "#     img_size = 100\n",
        "#     img = normalize(img)\n",
        "#     img = cv2.resize(img, (img_size, img_size))\n",
        "#     model_input = np.zeros((1, img_size, img_size, 3))\n",
        "#     model_input[0] = img\n",
        "#     genders = model_gender.predict(model_input)\n",
        "#     gender = genders[0]\n",
        "#     if gender > 0.5:\n",
        "#         print('Male')\n",
        "#     else:\n",
        "#         print('Female')\n",
        "#     return    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huWs2jy-2jT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = '/content/drive/My Drive/week10/face_detection'\n",
        "def face_id(filename, IMG_SIZE=160):\n",
        "    raw_img = cv2.imread(os.path.join(folder_path, filename))[:,:,::-1]\n",
        "    faces = detect_faces(raw_img)\n",
        "    if len(faces) == 0:\n",
        "        print('No face')\n",
        "        return\n",
        "    else:\n",
        "        # get face embeddings\n",
        "        face = faces[0]\n",
        "        # More predictions\n",
        "        predict_age(face)\n",
        "        # predict_emotion(face)\n",
        "        # predict_gender(face)\n",
        "        # # ID\n",
        "        # face = cv2.resize(face, (IMG_SIZE, IMG_SIZE))\n",
        "        # model_input = np.zeros((1, IMG_SIZE, IMG_SIZE, 3))\n",
        "        # model_input[0] = face\n",
        "        # model_input = preprocess(model_input)\n",
        "        # query_embeddings = feature_extractor.predict(model_input)\n",
        "        # query_embedding = query_embeddings[0]\n",
        "        \n",
        "        # # compute distance\n",
        "        # distances = np.zeros((len(embeddings)))\n",
        "        # for i, embed in enumerate(embeddings):\n",
        "        #     distance = euclidean_distance(embed, query_embedding)\n",
        "        #     distances[i] = distance\n",
        "\n",
        "        # # find min distance    \n",
        "        # idx_min = np.argmin(distances)\n",
        "        # distance, name = distances[idx_min], names[idx_min]\n",
        "        # print('name: ', name, ' distance: ',distance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGRrHjOu2tPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'face3.jpg'\n",
        "face_id(path)\n",
        "plt.imshow(cv2.imread(os.path.join(folder_path, path))[:,:,::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmkvTAM3F2m9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}