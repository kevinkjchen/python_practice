{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"43-1_FaceNet_mlp128-128.ipynb","provenance":[{"file_id":"11FVutJ-ji5oV_L3NQZYxD3pHZmyUdz6U","timestamp":1598945913717}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MMWSB22LC-Ba","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600280114516,"user_tz":-480,"elapsed":692,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"d5fedd90-6faa-4933-ac6d-7427c34a156f"},"source":["# 用單個模型同時執行兩個分類任務:\n","#   age 分成8個classes\n","#   gender 分成2個classes\n","# mlp 每個全連接層的unit個數: 128 - 128 -- 8\n","#                                       \\_ 2\n","# trainning: \n","#   改用generator產生資料給fit_generator\n","#   class_weight\n","#   random_state\n","#   callback: EarlyStop, model.save\n","\n","\n","#用少量資料\n","FULL_DATA = 0\n","per_cls_trn = 5 #400\n","per_cls_eval = 2 #10\n","#用全部資料\n","#FULL_DATA = 1\n","\n","IMG_SIZE = 160\n","BATCH_SIZE = 64\n","EPOCHS = 1\n","DROP_RATE = 0.4\n","#model_folder_path = 'drive/My Drive/Tibame_AIoT_Project/face'\n","model_folder_path = '/content/drive/My Drive/Tibame_AIoT_Project/KJ/Tibame_AIoT_Project'\n","img_folder_path = 'drive/My Drive/Tibame_AIoT_Project/Datasets/cleandataset'"],"execution_count":24,"outputs":[{"output_type":"stream","text":["time: 3.24 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-bv3RgQfbZ_r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600279224254,"user_tz":-480,"elapsed":270429,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"e3fb2ebf-387b-44e0-e54e-ccee05d31c95"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ri1ni0ZmaYPP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":196},"executionInfo":{"status":"ok","timestamp":1600279227878,"user_tz":-480,"elapsed":274045,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"6a6039f2-25aa-4374-b3a6-1dc49c0d9b9f"},"source":["# to measure execution time\n","!pip install ipython-autotime\n","%load_ext autotime"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting ipython-autotime\n","  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n","Building wheels for collected packages: ipython-autotime\n","  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1831 sha256=aa92bd84496f8a58879d7f0ec171ba00d39703de942360772c77bbac5c256b78\n","  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n","Successfully built ipython-autotime\n","Installing collected packages: ipython-autotime\n","Successfully installed ipython-autotime-0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WIxoBByJgDOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"status":"ok","timestamp":1600279227882,"user_tz":-480,"elapsed":274038,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"b561d352-307a-418c-937f-3cb0f5b79f72"},"source":["! nvidia-smi"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Wed Sep 16 18:00:29 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","time: 110 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Enr3u7SZ0rHX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"status":"ok","timestamp":1600279230391,"user_tz":-480,"elapsed":276540,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"a23c96c1-637f-45af-dba3-f4a3e8e3a58a"},"source":["!pip install mtcnn"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting mtcnn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n","Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.4.3)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.18.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n","Installing collected packages: mtcnn\n","Successfully installed mtcnn-0.1.0\n","time: 2.42 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"raO3mVLfMibC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600279348548,"user_tz":-480,"elapsed":394688,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"5570a238-fbb9-418a-ad5f-025e6e25a00d"},"source":["!pip install tensorflow==2.2.0\n","#!pip install tensorflow==2.3.0"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 33kB/s \n","\u001b[?25hCollecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 61.3MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.4)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.35.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.32.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.10.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n","Collecting tensorflow-estimator<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 50.5MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.3.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.18.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (50.3.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.17.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","Successfully installed tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n","time: 1min 58s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1HiBB7Hk1Cr-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600279351900,"user_tz":-480,"elapsed":398033,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"80fc0d43-dff4-45b1-94b1-ac903cd20eed"},"source":["import scipy.io\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime, timedelta\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","#import keras\n","#from keras.preprocessing.image import load_img\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\n","from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n","from keras.layers import Conv2D, AveragePooling2D, BatchNormalization\n","from keras.models import Model, Sequential\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","from keras import metrics\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from keras.models import load_model\n","import cv2\n","from glob import glob\n","import os\n","from mtcnn import MTCNN\n","import numpy as np"],"execution_count":7,"outputs":[{"output_type":"stream","text":["time: 3.31 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KvutOpBGdpVr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600279351903,"user_tz":-480,"elapsed":398027,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"2360292a-1254-4117-a141-304dc421173e"},"source":["print(tf.__version__)\n","print(keras.__version__)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["2.2.0\n","2.3.0-tf\n","time: 2.18 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hfiio5_KHufK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600279351906,"user_tz":-480,"elapsed":398023,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"0f924422-32a7-41d6-f6ba-54cee8d7f65c"},"source":["# 資料集由csv檔案讀入, 也可新增其他的csv檔案來擴充資料\n","# df = pd.read_csv('drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/age_gender_wiki.csv')\n","# df_under10 = pd.read_csv('drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/age_gender_imdb_under10.csv')\n","# df_over70 = pd.read_csv('drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/age_gender_imdb_over70.csv')\n","# df = pd.concat([df, df_under10, df_over70])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["time: 1.44 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hPi60EWkDL6K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600279356137,"user_tz":-480,"elapsed":402246,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"e6c9874e-987d-43fd-a2f2-fe89f82b97e7"},"source":["# cleandata: 清除wiki資料集原本的一些年齡標註錯誤\n","df = pd.read_csv(os.path.join(img_folder_path, 'cleandata.csv'))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["time: 3.95 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6vj29J-vpoyz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600279356139,"user_tz":-480,"elapsed":402239,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"544f658d-8c0d-435a-ad26-42cf134616ab"},"source":["#some guys seem to be greater than 100. some of these are paintings. remove these old guys\n","df = df[df['age'] <= 100]\n"," \n","#some guys seem to be unborn in the data set\n","df = df[df['age'] > 0]\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["time: 19.8 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZI0vTSSFtF3o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"status":"ok","timestamp":1600279356141,"user_tz":-480,"elapsed":402232,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"6ffc5583-c5d9-4588-9b0c-5b17f1d00e70"},"source":["# 每10歲分一類,70歲以上歸為同一類,共8類\n","df['age_grp'] = pd.cut(df['age'], bins=[0,10,20,30,40,50,60,70,110], right=False)\n","le = LabelEncoder()\n","le.fit(df['age_grp'].astype('str'))\n","df['age_cls'] = le.transform(df['age_grp'].astype('str'))\n","df"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>full_path</th>\n","      <th>gender</th>\n","      <th>age</th>\n","      <th>age_grp</th>\n","      <th>age_cls</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>f10/36890678_1955-04-19_1970.jpg</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>[10, 20)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>f10/36891092_1993-04-22_2012.jpg</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>[10, 20)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>f10/36897260_1993-07-16_2013.jpg</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>[10, 20)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>f10/46804145_1994-05-25_2014.jpg</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>[10, 20)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>f10/46812040_1999-01-05_2014.jpg</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>[10, 20)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>40098</th>\n","      <td>m0/img_3944_1.jpg</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>[0, 10)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>40099</th>\n","      <td>m0/img_3944_2.jpg</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>[0, 10)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>40100</th>\n","      <td>m0/img_3927_2.jpg</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>[0, 10)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>40101</th>\n","      <td>m0/img_3433_1.jpg</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>[0, 10)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>40102</th>\n","      <td>m0/img_3946_1.jpg</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>[0, 10)</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>40103 rows × 5 columns</p>\n","</div>"],"text/plain":["                              full_path  gender  age   age_grp  age_cls\n","0      f10/36890678_1955-04-19_1970.jpg       0   10  [10, 20)        1\n","1      f10/36891092_1993-04-22_2012.jpg       0   10  [10, 20)        1\n","2      f10/36897260_1993-07-16_2013.jpg       0   10  [10, 20)        1\n","3      f10/46804145_1994-05-25_2014.jpg       0   10  [10, 20)        1\n","4      f10/46812040_1999-01-05_2014.jpg       0   10  [10, 20)        1\n","...                                 ...     ...  ...       ...      ...\n","40098                 m0/img_3944_1.jpg       1    5   [0, 10)        0\n","40099                 m0/img_3944_2.jpg       1    5   [0, 10)        0\n","40100                 m0/img_3927_2.jpg       1    5   [0, 10)        0\n","40101                 m0/img_3433_1.jpg       1    5   [0, 10)        0\n","40102                 m0/img_3946_1.jpg       1    5   [0, 10)        0\n","\n","[40103 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"stream","text":["time: 345 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wBOpqcMoS90h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"ok","timestamp":1600279356147,"user_tz":-480,"elapsed":402230,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"7749a776-c252-47ba-b341-eb878a55f520"},"source":["df['age_cls'].value_counts().sort_index()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     1883\n","1     4120\n","2    11230\n","3     6518\n","4     4618\n","5     4199\n","6     5074\n","7     2461\n","Name: age_cls, dtype: int64"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"stream","text":["time: 8.75 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ynsfUWLDp4r7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"status":"ok","timestamp":1600279356750,"user_tz":-480,"elapsed":402826,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"628dfc70-1bf5-4173-dafe-091b8a645d2e"},"source":["histogram_age = df['age_cls'].hist(bins=df['age_cls'].nunique())"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["time: 191 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SC37vJjo_AB_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"status":"ok","timestamp":1600279356752,"user_tz":-480,"elapsed":402820,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"93fe94a8-c453-4498-e43d-cf55fa81415a"},"source":["histogram_gender = df['gender'].hist(bins=df['gender'].nunique())"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["time: 140 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YSCJlWc444MN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1600279356753,"user_tz":-480,"elapsed":402814,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"7790f940-6b25-4a53-ea28-1c038f6f3752"},"source":["#先用少量資料比較不同模型:\n","#每個類別各取部分資料,用train_test_split來切train and test\n","df_f0 = df[(df['age_cls'] == 0) & (df['gender'] == 0)]\n","df_f1 = df[(df['age_cls'] == 1) & (df['gender'] == 0)]\n","df_f2 = df[(df['age_cls'] == 2) & (df['gender'] == 0)]\n","df_f3 = df[(df['age_cls'] == 3) & (df['gender'] == 0)]\n","df_f4 = df[(df['age_cls'] == 4) & (df['gender'] == 0)]\n","df_f5 = df[(df['age_cls'] == 5) & (df['gender'] == 0)]\n","df_f6 = df[(df['age_cls'] == 6) & (df['gender'] == 0)]\n","df_f7 = df[(df['age_cls'] == 7) & (df['gender'] == 0)]\n","df_m0 = df[(df['age_cls'] == 0) & (df['gender'] == 1)]\n","df_m1 = df[(df['age_cls'] == 1) & (df['gender'] == 1)]\n","df_m2 = df[(df['age_cls'] == 2) & (df['gender'] == 1)]\n","df_m3 = df[(df['age_cls'] == 3) & (df['gender'] == 1)]\n","df_m4 = df[(df['age_cls'] == 4) & (df['gender'] == 1)]\n","df_m5 = df[(df['age_cls'] == 5) & (df['gender'] == 1)]\n","df_m6 = df[(df['age_cls'] == 6) & (df['gender'] == 1)]\n","df_m7 = df[(df['age_cls'] == 7) & (df['gender'] == 1)]\n","# train and val data\n","if FULL_DATA == 1:\n","    #每個類別保留最後per_cls_eval筆資料作為evaluate用\n","    train_df = pd.concat([\n","        df_f0[:-per_cls_eval], df_f1[:-per_cls_eval], df_f2[:-per_cls_eval], df_f3[:-per_cls_eval], \n","        df_f4[:-per_cls_eval], df_f5[:-per_cls_eval], df_f6[:-per_cls_eval], df_f7[:-per_cls_eval], \n","        df_m0[:-per_cls_eval], df_m1[:-per_cls_eval], df_m2[:-per_cls_eval], df_m3[:-per_cls_eval], \n","        df_m4[:-per_cls_eval], df_m5[:-per_cls_eval], df_m6[:-per_cls_eval], df_m7[:-per_cls_eval]         \n","        ])           \n","else:    \n","    #先用少量資料比較不同模型\n","    train_df = pd.concat([\n","        df_f0[:per_cls_trn], df_f1[:per_cls_trn], df_f2[:per_cls_trn], df_f3[:per_cls_trn], \n","        df_f4[:per_cls_trn], df_f5[:per_cls_trn], df_f6[:per_cls_trn], df_f7[:per_cls_trn], \n","        df_m0[:per_cls_trn], df_m1[:per_cls_trn], df_m2[:per_cls_trn], df_m3[:per_cls_trn], \n","        df_m4[:per_cls_trn], df_m5[:per_cls_trn], df_m6[:per_cls_trn], df_m7[:per_cls_trn]         \n","        ])\n","    \n","# evaluate data: 每個類別保留最後per_cls_eval筆資料作為evaluate用\n","eval_df = pd.concat([\n","        df_f0[-per_cls_eval:], df_f1[-per_cls_eval:], df_f2[-per_cls_eval:], df_f3[-per_cls_eval:], \n","        df_f4[-per_cls_eval:], df_f5[-per_cls_eval:], df_f6[-per_cls_eval:], df_f7[-per_cls_eval:],\n","        df_m0[-per_cls_eval:], df_m1[-per_cls_eval:], df_m2[-per_cls_eval:], df_m3[-per_cls_eval:], \n","        df_m4[-per_cls_eval:], df_m5[-per_cls_eval:], df_m6[-per_cls_eval:], df_m7[-per_cls_eval:]         \n","        ])\n","x_eval = np.array(eval_df['full_path'])\n","# 先把模型的兩個輸出的答案合併\n","y_eval = np.array(pd.concat([eval_df['age_cls'], eval_df['gender']], axis=1))\n","print(\"train:\", len(train_df), \"predict:\", len(eval_df))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["train: 80 predict: 32\n","time: 102 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PQi3zwjxagcW","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600279356754,"user_tz":-480,"elapsed":402807,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"43f5343e-e2df-46f0-84ae-ba97f4525fb2"},"source":["# 處理答案 把它轉成one-hot (後面再做)\n","# y_train_category = to_categorical(df['age_cls'], num_classes=8)\n","\n","# 2個輸出: age, gender\n","y_df = pd.concat([pd.DataFrame(train_df['age_cls']), pd.DataFrame(train_df['gender'])], axis=1)\n","\n","# 切分訓練data\n","x_train, x_test, y_train, y_test = train_test_split(np.array(train_df['full_path']), np.array(y_df), test_size=0.2, random_state=0)\n","\n","print(x_train[0], x_test[0], y_train[0], y_test[0])\n","print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["f0/170514_1963-03-06_1970.jpg m20/37807877_1987-08-20_2009.jpg [0 0] [2 1]\n","(64,) (16,) (64, 2) (16, 2)\n","time: 8.87 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FZJoKwSbtpb8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600279359038,"user_tz":-480,"elapsed":405085,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"15dbf99e-b964-49d2-99c2-9a0c2478cb1d"},"source":["detector = MTCNN()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["time: 2.31 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DypYAJ7cJlrC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600279359039,"user_tz":-480,"elapsed":405079,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"139c8421-4314-44cd-c9f2-b11ea5bbff68"},"source":["# # VGGFace: https://github.com/rcmalli/keras-vggface\n","# !pip install keras_vggface\n","# !pip install keras_applications\n","\n","# from keras_vggface.vggface import VGGFace\n","# from keras_vggface.utils import preprocess_input\n","# feature_extractor = VGGFace(model='senet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["time: 1.5 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3yhTDd3GnvWF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1600280134110,"user_tz":-480,"elapsed":9442,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"45ada45c-daee-4800-b0a8-75be3bf7a72f"},"source":["# FaceNet\n","feature_extractor = load_model(os.path.join(model_folder_path, 'facenet_keras.h5'))\n","#feature_extractor = load_model(os.path.join(model_folder_path, 'facenet.h5'))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","time: 8.74 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fOgsPn1i3E21","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600280145409,"user_tz":-480,"elapsed":677,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"9e159eb9-8c54-4473-c8ce-e23598010dc0"},"source":["feature_extractor.summary()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Model: \"inception_resnet_v1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n","__________________________________________________________________________________________________\n","Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n","__________________________________________________________________________________________________\n","Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_1_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n","                                                                 Block35_1_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_1_Activation (Activatio (None, 17, 17, 256)  0           Block35_1_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_2_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n","                                                                 Block35_2_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_2_Activation (Activatio (None, 17, 17, 256)  0           Block35_2_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_3_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n","                                                                 Block35_3_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_3_Activation (Activatio (None, 17, 17, 256)  0           Block35_3_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_4_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n","                                                                 Block35_4_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_4_Activation (Activatio (None, 17, 17, 256)  0           Block35_4_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_5_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n","                                                                 Block35_5_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_5_Activation (Activatio (None, 17, 17, 256)  0           Block35_5_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n","                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n","                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_1_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n","                                                                 Block17_1_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_1_Activation (Activatio (None, 8, 8, 896)    0           Block17_1_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_2_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n","                                                                 Block17_2_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_2_Activation (Activatio (None, 8, 8, 896)    0           Block17_2_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_3_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_3_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_3_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_3_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_3_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_3_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_3_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_3_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_3_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_3_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_3_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_2_Activation[0][0]       \n","                                                                 Block17_3_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_3_Activation (Activatio (None, 8, 8, 896)    0           Block17_3_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_4_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_4_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_4_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_4_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_4_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_4_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_4_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_4_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_4_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_4_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_4_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_3_Activation[0][0]       \n","                                                                 Block17_4_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_4_Activation (Activatio (None, 8, 8, 896)    0           Block17_4_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_5_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_5_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_5_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_5_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_5_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_5_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_5_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_5_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_5_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_5_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_5_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_4_Activation[0][0]       \n","                                                                 Block17_5_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_5_Activation (Activatio (None, 8, 8, 896)    0           Block17_5_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_6_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_6_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_6_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_6_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_6_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_6_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_6_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_6_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_6_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_6_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_6_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_5_Activation[0][0]       \n","                                                                 Block17_6_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_6_Activation (Activatio (None, 8, 8, 896)    0           Block17_6_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_7_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_7_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_7_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_7_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_7_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_7_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_7_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_7_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_7_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_7_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_7_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_6_Activation[0][0]       \n","                                                                 Block17_7_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_7_Activation (Activatio (None, 8, 8, 896)    0           Block17_7_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_8_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_8_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_8_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_8_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_8_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_8_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_8_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_8_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_8_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_8_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_8_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_7_Activation[0][0]       \n","                                                                 Block17_8_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_8_Activation (Activatio (None, 8, 8, 896)    0           Block17_8_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_9_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_9_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_9_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_9_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_9_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_9_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_9_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_9_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_9_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_9_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_9_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_8_Activation[0][0]       \n","                                                                 Block17_9_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_9_Activation (Activatio (None, 8, 8, 896)    0           Block17_9_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0a_1x1\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0a_1x1\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0a_1x1\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0b_1x7\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0b_1x7\n","__________________________________________________________________________________________________\n","Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0b_1x7\n","__________________________________________________________________________________________________\n","Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    384         Block17_10_Branch_0_Conv2d_1x1[0]\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0c_7x1\n","__________________________________________________________________________________________________\n","Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    0           Block17_10_Branch_0_Conv2d_1x1_Ba\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0c_7x1\n","__________________________________________________________________________________________________\n","Block17_10_Concatenate (Concate (None, 8, 8, 256)    0           Block17_10_Branch_0_Conv2d_1x1_Ac\n","                                                                 Block17_10_Branch_1_Conv2d_0c_7x1\n","__________________________________________________________________________________________________\n","Block17_10_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      Block17_10_Concatenate[0][0]     \n","__________________________________________________________________________________________________\n","Block17_10_ScaleSum (Lambda)    (None, 8, 8, 896)    0           Block17_9_Activation[0][0]       \n","                                                                 Block17_10_Conv2d_1x1[0][0]      \n","__________________________________________________________________________________________________\n","Block17_10_Activation (Activati (None, 8, 8, 896)    0           Block17_10_ScaleSum[0][0]        \n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    589824      Mixed_7a_Branch_2_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_0_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0b_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_0_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0b_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    884736      Mixed_7a_Branch_0_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_2_Conv2d_0b_3x3_A\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    1152        Mixed_7a_Branch_0_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_1_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_2_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    0           Mixed_7a_Branch_0_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_1_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_2_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_3_MaxPool_1a_3x (None, 3, 3, 896)    0           Block17_10_Activation[0][0]      \n","__________________________________________________________________________________________________\n","Mixed_7a (Concatenate)          (None, 3, 3, 1792)   0           Mixed_7a_Branch_0_Conv2d_1a_3x3_A\n","                                                                 Mixed_7a_Branch_1_Conv2d_1a_3x3_A\n","                                                                 Mixed_7a_Branch_2_Conv2d_1a_3x3_A\n","                                                                 Mixed_7a_Branch_3_MaxPool_1a_3x3[\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_1_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_1_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_1_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_1_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_1_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_1_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_1_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_1_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_1_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_1_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_1_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Mixed_7a[0][0]                   \n","                                                                 Block8_1_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_1_Activation (Activation (None, 3, 3, 1792)   0           Block8_1_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_2_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_2_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_2_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_2_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_2_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_2_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_2_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_2_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_2_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_2_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_2_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_1_Activation[0][0]        \n","                                                                 Block8_2_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_2_Activation (Activation (None, 3, 3, 1792)   0           Block8_2_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_3_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_3_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_3_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_3_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_3_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_3_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_3_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_3_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_3_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_3_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_3_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_2_Activation[0][0]        \n","                                                                 Block8_3_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_3_Activation (Activation (None, 3, 3, 1792)   0           Block8_3_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_4_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_4_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_4_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_4_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_4_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_4_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_4_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_4_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_4_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_4_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_4_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_3_Activation[0][0]        \n","                                                                 Block8_4_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_4_Activation (Activation (None, 3, 3, 1792)   0           Block8_4_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_5_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_5_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_5_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_5_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_5_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_5_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_5_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_5_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_5_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_5_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_5_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_4_Activation[0][0]        \n","                                                                 Block8_5_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_5_Activation (Activation (None, 3, 3, 1792)   0           Block8_5_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_6_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_6_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_6_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_6_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_6_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_6_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_6_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_6_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_6_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_6_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_6_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_5_Activation[0][0]        \n","                                                                 Block8_6_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","AvgPool (GlobalAveragePooling2D (None, 1792)         0           Block8_6_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Dropout (Dropout)               (None, 1792)         0           AvgPool[0][0]                    \n","__________________________________________________________________________________________________\n","Bottleneck (Dense)              (None, 128)          229376      Dropout[0][0]                    \n","__________________________________________________________________________________________________\n","Bottleneck_BatchNorm (BatchNorm (None, 128)          384         Bottleneck[0][0]                 \n","==================================================================================================\n","Total params: 22,808,144\n","Trainable params: 22,779,312\n","Non-trainable params: 28,832\n","__________________________________________________________________________________________________\n","time: 99.8 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7iJ6QxgZ_8iI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600280163360,"user_tz":-480,"elapsed":742,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"92518dcb-166c-4eed-ea10-98b09c01e1a2"},"source":["# 固定pre-train model的參數\n","for lyr in feature_extractor.layers:\n","    lyr.trainable = False\n","\n","# BN\n","x = BatchNormalization()(feature_extractor.output)    \n","    \n","# MLP    \n","# x = Flatten()(x)\n","x = Dropout(DROP_RATE)(x)\n","x = Dense(units=128, activation='relu')(x)\n","x = Dropout(DROP_RATE)(x)\n","x = Dense(units=128, activation='relu')(x)\n","x = Dropout(DROP_RATE)(x)\n","age = Dense(units=8, activation='softmax', name='age')(x)\n","gender = Dense(units=2, activation='softmax', name='gender')(x)\n","\n","inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n","# 2個輸出: age, gender\n","age_gender_model = Model(inputs=feature_extractor.input, outputs=[age, gender])   \n","age_gender_model.summary()"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n","__________________________________________________________________________________________________\n","Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n","__________________________________________________________________________________________________\n","Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n","__________________________________________________________________________________________________\n","Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_1_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n","                                                                 Block35_1_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_1_Activation (Activatio (None, 17, 17, 256)  0           Block35_1_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_2_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n","                                                                 Block35_2_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_2_Activation (Activatio (None, 17, 17, 256)  0           Block35_2_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_3_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n","                                                                 Block35_3_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_3_Activation (Activatio (None, 17, 17, 256)  0           Block35_3_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_4_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n","                                                                 Block35_4_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_4_Activation (Activatio (None, 17, 17, 256)  0           Block35_4_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n","__________________________________________________________________________________________________\n","Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n","                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n","                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n","__________________________________________________________________________________________________\n","Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block35_5_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n","                                                                 Block35_5_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block35_5_Activation (Activatio (None, 17, 17, 256)  0           Block35_5_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n","                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n","                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_1_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n","                                                                 Block17_1_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_1_Activation (Activatio (None, 8, 8, 896)    0           Block17_1_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_2_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n","                                                                 Block17_2_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_2_Activation (Activatio (None, 8, 8, 896)    0           Block17_2_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_3_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_3_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_3_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_3_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_3_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_3_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_3_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_3_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_3_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_3_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_3_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_2_Activation[0][0]       \n","                                                                 Block17_3_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_3_Activation (Activatio (None, 8, 8, 896)    0           Block17_3_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_4_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_4_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_4_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_4_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_4_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_4_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_4_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_4_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_4_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_4_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_4_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_3_Activation[0][0]       \n","                                                                 Block17_4_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_4_Activation (Activatio (None, 8, 8, 896)    0           Block17_4_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_5_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_5_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_5_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_5_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_5_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_5_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_5_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_5_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_5_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_5_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_5_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_4_Activation[0][0]       \n","                                                                 Block17_5_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_5_Activation (Activatio (None, 8, 8, 896)    0           Block17_5_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_6_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_6_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_6_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_6_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_6_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_6_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_6_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_6_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_6_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_6_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_6_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_5_Activation[0][0]       \n","                                                                 Block17_6_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_6_Activation (Activatio (None, 8, 8, 896)    0           Block17_6_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_7_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_7_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_7_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_7_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_7_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_7_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_7_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_7_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_7_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_7_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_7_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_6_Activation[0][0]       \n","                                                                 Block17_7_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_7_Activation (Activatio (None, 8, 8, 896)    0           Block17_7_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_8_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_8_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_8_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_8_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_8_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_8_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_8_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_8_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_8_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_8_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_8_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_7_Activation[0][0]       \n","                                                                 Block17_8_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_8_Activation (Activatio (None, 8, 8, 896)    0           Block17_8_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0a_1x1[\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0a_1x1_\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0b_1x7[\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_9_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0b_1x7_\n","__________________________________________________________________________________________________\n","Block17_9_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_9_Branch_0_Conv2d_1x1[0][\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0c_7x1[\n","__________________________________________________________________________________________________\n","Block17_9_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_9_Branch_0_Conv2d_1x1_Bat\n","__________________________________________________________________________________________________\n","Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_9_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_9_Branch_0_Conv2d_1x1_Act\n","                                                                 Block17_9_Branch_1_Conv2d_0c_7x1_\n","__________________________________________________________________________________________________\n","Block17_9_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_9_Concatenate[0][0]      \n","__________________________________________________________________________________________________\n","Block17_9_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_8_Activation[0][0]       \n","                                                                 Block17_9_Conv2d_1x1[0][0]       \n","__________________________________________________________________________________________________\n","Block17_9_Activation (Activatio (None, 8, 8, 896)    0           Block17_9_ScaleSum[0][0]         \n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0a_1x1\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0a_1x1\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0a_1x1\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0b_1x7\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0b_1x7\n","__________________________________________________________________________________________________\n","Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0b_1x7\n","__________________________________________________________________________________________________\n","Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    384         Block17_10_Branch_0_Conv2d_1x1[0]\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0c_7x1\n","__________________________________________________________________________________________________\n","Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    0           Block17_10_Branch_0_Conv2d_1x1_Ba\n","__________________________________________________________________________________________________\n","Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0c_7x1\n","__________________________________________________________________________________________________\n","Block17_10_Concatenate (Concate (None, 8, 8, 256)    0           Block17_10_Branch_0_Conv2d_1x1_Ac\n","                                                                 Block17_10_Branch_1_Conv2d_0c_7x1\n","__________________________________________________________________________________________________\n","Block17_10_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      Block17_10_Concatenate[0][0]     \n","__________________________________________________________________________________________________\n","Block17_10_ScaleSum (Lambda)    (None, 8, 8, 896)    0           Block17_9_Activation[0][0]       \n","                                                                 Block17_10_Conv2d_1x1[0][0]      \n","__________________________________________________________________________________________________\n","Block17_10_Activation (Activati (None, 8, 8, 896)    0           Block17_10_ScaleSum[0][0]        \n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    589824      Mixed_7a_Branch_2_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_0_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0b_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_0_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0b_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    884736      Mixed_7a_Branch_0_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_2_Conv2d_0b_3x3_A\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    1152        Mixed_7a_Branch_0_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_1_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_2_Conv2d_1a_3x3[0\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    0           Mixed_7a_Branch_0_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_1_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_2_Conv2d_1a_3x3_B\n","__________________________________________________________________________________________________\n","Mixed_7a_Branch_3_MaxPool_1a_3x (None, 3, 3, 896)    0           Block17_10_Activation[0][0]      \n","__________________________________________________________________________________________________\n","Mixed_7a (Concatenate)          (None, 3, 3, 1792)   0           Mixed_7a_Branch_0_Conv2d_1a_3x3_A\n","                                                                 Mixed_7a_Branch_1_Conv2d_1a_3x3_A\n","                                                                 Mixed_7a_Branch_2_Conv2d_1a_3x3_A\n","                                                                 Mixed_7a_Branch_3_MaxPool_1a_3x3[\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_1_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_1_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_1_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_1_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_1_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_1_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_1_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_1_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_1_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_1_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_1_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Mixed_7a[0][0]                   \n","                                                                 Block8_1_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_1_Activation (Activation (None, 3, 3, 1792)   0           Block8_1_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_2_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_2_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_2_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_2_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_2_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_2_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_2_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_2_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_2_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_2_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_2_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_1_Activation[0][0]        \n","                                                                 Block8_2_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_2_Activation (Activation (None, 3, 3, 1792)   0           Block8_2_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_3_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_3_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_3_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_3_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_3_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_3_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_3_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_3_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_3_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_3_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_3_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_2_Activation[0][0]        \n","                                                                 Block8_3_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_3_Activation (Activation (None, 3, 3, 1792)   0           Block8_3_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_4_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_4_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_4_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_4_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_4_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_4_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_4_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_4_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_4_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_4_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_4_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_3_Activation[0][0]        \n","                                                                 Block8_4_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_4_Activation (Activation (None, 3, 3, 1792)   0           Block8_4_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_5_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_5_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_5_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_5_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_5_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_5_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_5_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_5_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_5_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_5_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_5_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_4_Activation[0][0]        \n","                                                                 Block8_5_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","Block8_5_Activation (Activation (None, 3, 3, 1792)   0           Block8_5_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0a_1x1[0\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0a_1x1_B\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0a_1x1_A\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0b_1x3[0\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0b_1x3_B\n","__________________________________________________________________________________________________\n","Block8_6_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0b_1x3_A\n","__________________________________________________________________________________________________\n","Block8_6_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_6_Branch_0_Conv2d_1x1[0][0\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0c_3x1[0\n","__________________________________________________________________________________________________\n","Block8_6_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_6_Branch_0_Conv2d_1x1_Batc\n","__________________________________________________________________________________________________\n","Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0c_3x1_B\n","__________________________________________________________________________________________________\n","Block8_6_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_6_Branch_0_Conv2d_1x1_Acti\n","                                                                 Block8_6_Branch_1_Conv2d_0c_3x1_A\n","__________________________________________________________________________________________________\n","Block8_6_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_6_Concatenate[0][0]       \n","__________________________________________________________________________________________________\n","Block8_6_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_5_Activation[0][0]        \n","                                                                 Block8_6_Conv2d_1x1[0][0]        \n","__________________________________________________________________________________________________\n","AvgPool (GlobalAveragePooling2D (None, 1792)         0           Block8_6_ScaleSum[0][0]          \n","__________________________________________________________________________________________________\n","Dropout (Dropout)               (None, 1792)         0           AvgPool[0][0]                    \n","__________________________________________________________________________________________________\n","Bottleneck (Dense)              (None, 128)          229376      Dropout[0][0]                    \n","__________________________________________________________________________________________________\n","Bottleneck_BatchNorm (BatchNorm (None, 128)          384         Bottleneck[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 128)          512         Bottleneck_BatchNorm[0][0]       \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 128)          0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 128)          16512       dropout[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 128)          16512       dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 128)          0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","age (Dense)                     (None, 8)            1032        dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","gender (Dense)                  (None, 2)            258         dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 22,842,970\n","Trainable params: 34,570\n","Non-trainable params: 22,808,400\n","__________________________________________________________________________________________________\n","time: 228 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hev5u-W9MLXn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1kkxVLcXJ28V6h_AkE5N5VZJeYBvVUPLS"},"executionInfo":{"status":"ok","timestamp":1600280189971,"user_tz":-480,"elapsed":23577,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"1bd94d5e-0615-45c9-993f-aefb40f34be6"},"source":["from keras.utils import plot_model\n","plot_model(age_gender_model, show_shapes=True)"],"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"Bs6tioz-AvmI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600280190365,"user_tz":-480,"elapsed":2941,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"26675d17-0a49-4dcc-cf06-f8a9f90ae1f5"},"source":["age_gender_model.compile(loss=[\"categorical_crossentropy\",\"binary_crossentropy\"], \n","                  optimizer='adam', metrics=[{'age':'accuracy'},{'gender':'accuracy'}]) # 2個輸出: age, gender\n","#age_gender_model.load_weights(os.path.join(model_folder_path,'21-1_senet_mlp128_bs64.h5'))\n","#model  =  load_model(os.path.join(model_folder_path,'43-1_FaceNet_mlp128-128_bs64_save.h5'))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["time: 32.3 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D-Mn0wTy5Bze","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600280214150,"user_tz":-480,"elapsed":798,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"3794c033-21fd-4e8f-87e5-9a896c97ba8b"},"source":["# 資料預處理 for facenet?\n","# Standardization\n","def preprocess(imgs): \n","    for i in range(imgs.shape[0]):\n","        # standardization\n","        img = imgs[i]\n","        mean, std = img.mean(), img.std()\n","        img = (img - mean) / std\n","        imgs[i] = img\n","    return imgs\n","# # Normalization\n","# def normalize(img):\n","#     return img / 255.\n","\n","# # -1 <= x <= 1\n","# def preprocess_1(imgs):\n","#     x = np.array(imgs, dtype = float)\n","#     x /= 127.5\n","#     x -= 1.\n","#     return x    "],"execution_count":30,"outputs":[{"output_type":"stream","text":["time: 4.96 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"evAgdxQ20ICI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600280216347,"user_tz":-480,"elapsed":946,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"8dab7b55-b8c5-401a-c16a-59d53636bafc"},"source":["# detect face\n","def detect_faces(img):\n","    face_imgs = []\n","\n","    results = detector.detect_faces(img)\n","    # extract the bounding box from the first face\n","    # print('# of faces: ', len(results))\n","    for i in range(len(results)):\n","        x1, y1, width, height = results[i]['box']\n","        x2, y2 = x1 + width, y1 + height\n","        patch = img[y1:y2, x1:x2] # crop face\n","        face_imgs.append(patch)\n","     \n","    return face_imgs"],"execution_count":31,"outputs":[{"output_type":"stream","text":["time: 3.66 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c8gr0xxA9NwP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600280218174,"user_tz":-480,"elapsed":1046,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"1a5e29c4-7dee-4442-8c31-072e35519bf2"},"source":["from tensorflow.keras.utils import Sequence\n","class DataGenerator(Sequence):\n","    \"\"\"\n","    Generates data for Keras\n","    ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n","    \"\"\"\n","    def __init__(self,\n","                 paths,\n","                 y_cls,\n","                 batch_size,\n","                 #num_classes,\n","                 shuffle=False):\n","        self.paths = paths\n","        self.y_cls = y_cls\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        #self.num_classes = num_classes\n","        self.indexes = np.arange(len(self.paths))\n","        #self.class_map = {'0':0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7}\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'number of batches per epoch'\n","        return int(np.ceil(len(self.paths) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","\n","        # Generate indexes of the batch\n","        idxs = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        batch_paths = [self.paths[i] for i in idxs]\n","        batch_y = [self.y_cls[i] for i in idxs]\n","\n","        # Generate data\n","        X, y = self.__data_generation(batch_paths, batch_y)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, paths, y_cls):\n","        \"\"\"\n","        Generates data containing batch_size samples\n","        \"\"\"\n","        # X = np.empty((len(paths), IMG_SIZE, IMG_SIZE, 3), dtype=np.float32)\n","        # y = np.empty((len(paths), self.num_classes), dtype=np.float32)\n","\n","        x_ori, x_norm, y_age, y_gender = [], [], [], []\n","\n","        for i, path in enumerate(paths):\n","            #print(\"idx:\", i, \"cls:\", y_cls[i], path)\n","        \n","            # 讀取圖片,切下臉的部分,並使用借來的模型的預處理方式來作預處理           \n","            img = cv2.imread(os.path.join(img_folder_path,path))[:,:,::-1]\n","            faces = detect_faces(img)\n","            if len(faces) == 0 or faces[0].shape[0] == 0 or faces[0].shape[1] == 0:\n","                print(' No face')\n","                continue\n","            #print(faces[0].shape)   \n","            img_crop = cv2.resize(faces[0], (IMG_SIZE, IMG_SIZE))\n","\n","            # 使用FaceNet模型的預處理方式來作預處理\n","            img_pre = preprocess(np.array(img_crop,dtype=float))\n","            \n","            # 把原圖留下來\n","            x_ori.append(img)\n","            x_norm.append(img_pre)\n","            y_age.append(y_cls[i][0])\n","            y_gender.append(y_cls[i][1])\n","\n","            \n","\n","        # print(\"len(image_data)\",len(x_ori))\n","        # plt.figure(figsize=(10, 40))\n","        # for j,m in enumerate(x_ori):\n","        #     plt.subplot(1, BATCH_SIZE, (j%BATCH_SIZE)+1)\n","        #     plt.title(\"idx:{} y_cls:{}\".format(i_batch+j, y_cls[i_batch+j]))\n","        #     plt.axis(\"off\")\n","        #     plt.imshow(m)\n","        # plt.show() \n","\n","        \n","        # 2個輸出: age, gender  \n","        # print(type(y_age), len(y_age), y_age[:8])\n","        # print(type(y_gender), len(y_gender), y_gender[:8])\n","        y_age_category = to_categorical(y_age, num_classes=8) \n","        y_gender_category = to_categorical(y_gender, num_classes=2) \n","        # print(y_age_category)\n","        # print(y_gender_category)\n","        x_input = {'input_1':np.array(x_norm)}\n","        y_category = {'age':np.array(y_age_category), 'gender':np.array(y_gender_category)}\n","        # print(type(np.array(x_norm)), np.array(x_norm).shape)\n","        # print(type(y_category), np.array(y_age_category), np.array(y_gender_category))\n","\n","        #yield x_input, y_category\n","        return x_input, y_category"],"execution_count":32,"outputs":[{"output_type":"stream","text":["time: 75 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3DidZIPzKHzS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600280220393,"user_tz":-480,"elapsed":1212,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"6945b794-98d2-4b69-9781-e42382fc6e9b"},"source":["# 用generator產生資料\n","generator_train = DataGenerator(x_train, y_train, batch_size=BATCH_SIZE)\n","generator_test = DataGenerator(x_test, y_test, batch_size=BATCH_SIZE)\n","#type(generator_train)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["time: 1.32 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZEWln4Tua3dg","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600280222338,"user_tz":-480,"elapsed":1045,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"e7687594-a210-4a94-9ee0-627e0959ae74"},"source":["# if FULL_DATA == 1:\n","#     age_weights = {0:12., 1:5., 2:1., 3:2., 4:3., 5:4., 6:6., 7:3.}\n","# else:    \n","#     # for temp\n","#     age_weights = {0:1., 1:1., 2:1., 3:1., 4:1., 5:1., 6:1., 7:1.}\n","\n","# data_count = np.unique(np.argmax(y_train, axis=-1), return_counts=True)[1]\n","# data_count\n","# num_classes=8\n","# age_weights = (1/data_count)*np.sum(data_count)/num_classes\n","# class_weight = {i: w for i, w in enumerate(age_weights)}\n","# print('class_weight', class_weight)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["time: 1.41 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jc_L3HTVMio7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600280340787,"user_tz":-480,"elapsed":117712,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"5af5c5ed-da81-4e16-8e27-ebc4aad1dbfa"},"source":["# fit_generator\n","checkpoint = ModelCheckpoint(os.path.join(model_folder_path,\"43-1_FaceNet_mlp128-128_bs64_ep{epoch}_{val_age_accuracy:.4f}_{val_gender_accuracy:.4f}.h5\"), \n","               save_best_only=False, save_weights_only=False)   #Defaults: save_freq='epoch', save_weights_only=False\n","earlystop = EarlyStopping(patience=5, restore_best_weights=True)\n","#logs = age_gender_model.fit_generator(\n","logs = age_gender_model.fit( \n","        generator_train,\n","        #steps_per_epoch=len(x_train)//BATCH_SIZE,\n","        epochs=EPOCHS,\n","        validation_data=generator_test,\n","        #validation_steps=len(x_test)//BATCH_SIZE,\n","        callbacks=[checkpoint, earlystop] \n","        )"],"execution_count":35,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 22 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:10 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 22 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 24 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:9 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:10 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 33 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 34 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 38 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 39 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:5 out of the last 34 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 38 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 40 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","1/1 [==============================] - ETA: 0s - loss: 3.7461 - age_loss: 2.5072 - gender_loss: 1.2389 - age_accuracy: 0.2500 - gender_accuracy: 0.4844WARNING:tensorflow:5 out of the last 30 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:6 out of the last 31 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:7 out of the last 32 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","WARNING:tensorflow:8 out of the last 33 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f14f8f2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","1/1 [==============================] - 18s 18s/step - loss: 3.7461 - age_loss: 2.5072 - gender_loss: 1.2389 - age_accuracy: 0.2500 - gender_accuracy: 0.4844 - val_loss: 2.9487 - val_age_loss: 2.1158 - val_gender_loss: 0.8329 - val_age_accuracy: 0.1875 - val_gender_accuracy: 0.4375\n","time: 1min 56s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uo-ObdSowPvw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600280343444,"user_tz":-480,"elapsed":114671,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"3c93e5f2-952f-4dba-be29-4ab846f697f5"},"source":["age_gender_model.save(os.path.join(model_folder_path,'43-1_FaceNet_mlp128-128_bs64_save.h5'))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["time: 2.32 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BrS_mOX64Uv7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600280349372,"user_tz":-480,"elapsed":115542,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"91935b7e-1f58-424c-917d-c81c884a7895"},"source":["model = load_model(os.path.join(model_folder_path,\"43-1_FaceNet_mlp128-128_bs64_save.h5\"))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["time: 5.97 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"luQDTgMI4tGl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":586},"executionInfo":{"status":"ok","timestamp":1600280356515,"user_tz":-480,"elapsed":120649,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"041606d3-fff6-44a5-9d6d-399a598e05ae"},"source":["!pip install keras2onnx"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Collecting keras2onnx\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2f/c7aef8f8215c62d55ea05f5b36737c1726e4fea6c73970909523ae497fd9/keras2onnx-1.7.0-py3-none-any.whl (96kB)\n","\u001b[K     |████████████████████████████████| 102kB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (3.12.4)\n","Collecting fire\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n","\u001b[?25hCollecting onnx\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/ee/bc7bc88fc8449266add978627e90c363069211584b937fd867b0ccc59f09/onnx-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (7.4MB)\n","\u001b[K     |████████████████████████████████| 7.4MB 23.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (2.23.0)\n","Collecting onnxconverter-common>=1.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/7a/7e30c643cd7d2ad87689188ef34ce93e657bd14da3605f87bcdbc19cd5b1/onnxconverter_common-1.7.0-py2.py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (1.18.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->keras2onnx) (50.3.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->keras2onnx) (1.15.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire->keras2onnx) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->keras2onnx) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (3.0.4)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=26d891ef135a635e1c1d239c2b42ec1cc3bb77265abfeaac7dd86cbb773c4941\n","  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n","Successfully built fire\n","Installing collected packages: fire, onnx, onnxconverter-common, keras2onnx\n","Successfully installed fire-0.3.1 keras2onnx-1.7.0 onnx-1.7.0 onnxconverter-common-1.7.0\n","time: 7.46 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lCHxkdwCDnam","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"status":"error","timestamp":1600280360326,"user_tz":-480,"elapsed":118963,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"efa112bf-f33e-40e2-e227-986f4aaa430b"},"source":["# convert to onnx model\n","import keras2onnx\n","onnx_model = keras2onnx.convert_keras(model, model.name)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["tf executing eager_mode: True\n","tf.keras model eager_mode: False\n"],"name":"stderr"},{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-debb141651f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert to onnx model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras2onnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras2onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras2onnx/main.py\u001b[0m in \u001b[0;36mconvert_keras\u001b[0;34m(model, name, doc_string, target_opset, channel_first_inputs, debug_mode, custom_op_conversions)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_topology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_opset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_first_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras2onnx/topology.py\u001b[0m in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, channel_first_inputs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mextra_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_extra_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_remove_unused_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras2onnx/topology.py\u001b[0m in \u001b[0;36m_remove_unused_nodes\u001b[0;34m(nodes, inputs, outputs)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0min_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0min_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                     \u001b[0;34m\"{} is disconnected, check the parsing log for more details.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnd_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnd_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_to_keep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Block8_6_Branch_0_Conv2d_1x1_BatchNorm_1/cond/input_0:01 is disconnected, check the parsing log for more details."]},{"output_type":"stream","text":["time: 3.65 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w-KrqZ3kEKet","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600280360322,"user_tz":-480,"elapsed":116948,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["keras2onnx.save_model(onnx_model, os.path.join(model_folder_path,'FaceNet_128-128.onnx'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_zCJfVyisiK","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359379,"user_tz":-480,"elapsed":405312,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["history = logs.history\n","history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETe6gpnqjZzx","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359380,"user_tz":-480,"elapsed":405312,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["plt.plot(history['age_accuracy'])\n","plt.plot(history['val_age_accuracy'])\n","plt.legend(['age_accuracy', 'val_age_accuracy'])\n","plt.title('age_accuracy')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PYa3D33Gi_Yx","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359381,"user_tz":-480,"elapsed":405309,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["plt.plot(history['gender_accuracy'])\n","plt.plot(history['val_gender_accuracy'])\n","plt.legend(['gender_accuracy', 'val_gender_accuracy'])\n","plt.title('gender_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eibGTK-gjaTU","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359381,"user_tz":-480,"elapsed":405307,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["plt.plot(history['age_loss'])\n","plt.plot(history['val_age_loss'])\n","plt.legend(['age_loss', 'val_age_loss'])\n","plt.title('age_loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bMECQHoybWq0","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359383,"user_tz":-480,"elapsed":405307,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["plt.plot(history['gender_loss'])\n","plt.plot(history['val_gender_loss'])\n","plt.legend(['gender_loss', 'val_gender_loss'])\n","plt.title('gender_loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBpYGPqZDTkT","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359383,"user_tz":-480,"elapsed":405304,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["# 取得要預測的圖片並做預處理\n","def get_preprocess_images(data_paths, y_data, batch_size=BATCH_SIZE):\n","    n = len(data_paths)\n","    # i = 0\n","    # data_paths = data_paths\n","    \n","    #while i < n:    \n","    x_ori, x_norm, y_age, y_gender = [], [], [], []\n","    #i_batch = i\n","    for idx in range(batch_size):\n","        path = data_paths[idx]\n","        #print(\"n:\", n, \"idx:\", i, \"cls:\", y_data[i], path)\n","    \n","        # 讀取圖片,切下臉的部分,並使用借來的模型的預處理方式來作預處理 \n","        try:          \n","            img = cv2.imread(os.path.join(img_folder_path,path))[:,:,::-1]\n","        except:\n","            print('imread failed')\n","            idx = idx + 1\n","            continue                   \n","        \n","        faces = detect_faces(img)\n","        if len(faces) == 0 or faces[0].shape[0] == 0 or faces[0].shape[1] == 0:\n","            print('No face')\n","            idx = idx + 1\n","            continue   \n","        # print(faces[0].shape)    \n","        img_crop = cv2.resize(faces[0], (IMG_SIZE, IMG_SIZE))\n","        \n","\n","        # 使用FaceNet模型的預處理方式來作預處理\n","        img_pre = preprocess(np.array(img_crop,dtype=float)\n","\n","        # 把原圖留下來\n","        x_ori.append(img)\n","        x_norm.append(img_pre)\n","        if len(y_data) != 0:\n","            y_age.append(y_data[idx][0])\n","            y_gender.append(y_data[idx][1])\n","        \n","        idx = idx + 1\n","\n","\n","    # print(\"len(image_data)\",len(x_ori))\n","    # plt.figure(figsize=(10, 40))\n","    # for j,m in enumerate(x_ori):\n","    #     plt.subplot(1, BATCH_SIZE, (j%BATCH_SIZE)+1)\n","    #     plt.title(\"idx:{} y_data:{}\".format(i_batch+j, y_data[i_batch+j]))\n","    #     plt.axis(\"off\")\n","    #     plt.imshow(m)\n","    # plt.show() \n","\n","    \n","    # 2個輸出: age, gender  \n","    # print(type(y_age), len(y_age), y_age[:8])\n","    # print(type(y_gender), len(y_gender), y_gender[:8])\n","    if len(y_data) != 0:\n","        y_age_category = to_categorical(y_age, num_classes=8) \n","        y_gender_category = to_categorical(y_gender, num_classes=2) \n","        y_category = {'age':np.array(y_age_category), 'gender':np.array(y_gender_category)}\n","    else:\n","        y_category = []\n","\n","    # print(type(np.array(x_norm)), np.array(x_norm).shape)\n","    # print(type(y_category), np.array(y_age_category), np.array(y_gender_category))\n","\n","    return np.array(x_ori), np.array(x_norm), y_category\n","    #print('while end', i, n)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ngKRFAYgS5Zd","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359383,"user_tz":-480,"elapsed":405301,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["# evaluate\n","#\n","# 從保留作為evaluate用的資料,用generator產生資料 to predict\n","x_ori, x_input, y_category = get_preprocess_images(x_eval, y_eval, batch_size=len(x_eval))\n","\n","# 取出圖片資料與正確答案\n","x_eval_data, y_true_age, y_true_gender = [], [], []\n","for i,x in enumerate(x_input):\n","    # print(\"x_eval_data:\", len(list(x_dict['input_4'])))\n","    x_eval_data.append(x)\n","    # print(\"y_true_age:\", y_dict['age'].argmax(axis=-1))\n","    # print(\"y_true_gender:\", y_dict['gender'].argmax(axis=-1))    \n","    y_true_age.append( (list(y_category['age'])[i].argmax(axis=-1)) )\n","    y_true_gender.append( (list(y_category['gender'])[i].argmax(axis=-1)) )\n","\n","# print(\"-------------------------\")\n","print(\"x_eval_data:\", type(x_eval_data), \"np.array:\", np.array(x_eval_data).shape, x_eval[:8])\n","print(\"y_true_age:\", y_true_age)\n","print(\"y_true_gender:\", y_true_gender)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0VkMu89Pn36","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359384,"user_tz":-480,"elapsed":405301,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["# predict\n","pre = age_gender_model.predict(np.array(x_eval_data))\n","#pre[0] is predicted probabilities for age\n","#pre[1] is predicted probabilities for gender\n","pred_age = pre[0].argmax(axis=-1)\n","pred_gender = pre[1].argmax(axis=-1)\n","print(\"predict age:\",pred_age)\n","print(\"predict gender:\",pred_gender)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkfU4iT97pGb","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359385,"user_tz":-480,"elapsed":405301,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["len(pred_age), len(pred_gender)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6P7GHnZJ58DJ","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359385,"user_tz":-480,"elapsed":405299,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["from sklearn.metrics import classification_report\n","print(np.array(y_true_age).shape, np.array(pred_age).shape, np.array(y_true_gender).shape, np.array(pred_gender).shape)\n","age_target_names = [str(i) for i in range(8)]\n","gender_target_names = [str(i) for i in range(2)]\n","print(classification_report(np.array(y_true_age), np.array(pred_age), target_names=age_target_names))\n","print(classification_report(np.array(y_true_gender), np.array(pred_gender), target_names=gender_target_names))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3pFTzAkoWIiT","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359386,"user_tz":-480,"elapsed":405297,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["from sklearn.metrics import confusion_matrix\n","pd.DataFrame(confusion_matrix(y_true_age, pred_age),\n","            index=[\"{}(真實)\".format(i) for i in range(8)],\n","            columns=[\"{}(預測)\".format(i) for i in range(8)] \n","            )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVTIZJsXZyjn","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359387,"user_tz":-480,"elapsed":405294,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":["pd.DataFrame(confusion_matrix(y_true_gender, pred_gender),\n","            index=[\"{}(真實)\".format(i) for i in range(2)],\n","            columns=[\"{}(預測)\".format(i) for i in range(2)] \n","            )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LdyuPoYL6Q7K","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600279359388,"user_tz":-480,"elapsed":405292,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}}},"source":[""],"execution_count":null,"outputs":[]}]}